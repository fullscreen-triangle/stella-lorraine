
\subsection{Controller as Maxwell Demon}

The categorical memory controller operates as a Maxwell demon in information space. The controller observes precision-by-difference values (categorical information) and uses them to sort data across memory tiers (hot vs.\ cold), analogous to the original demon sorting molecules by velocity (fast vs.\ slow). Figure~\ref{fig:categorical_memory}(F) illustrates the demon schematically, showing how it mediates between fast tier (hot data, filled circles) and slow tier (cold data, empty circles).

\begin{definition}[Categorical Memory Demon]
The categorical memory demon $\mathcal{D}$ is an agent that:
\begin{enumerate}
    \item Observes precision-by-difference values from hardware oscillators
    \item Computes S-entropy coordinates from precision signatures
    \item Determines categorical proximity of stored data to current position
    \item Moves data between tiers based on proximity (promotion/demotion)
    \item Predicts future access patterns through trajectory completion
\end{enumerate}
\end{definition}

The demon's performance is validated in Figure~\ref{fig:categorical_memory_operations}(C), which shows 157 precision-by-difference calculations, 33 total hits, and zero evictions---demonstrating that categorical completion correctly predicts optimal tier placement.

\subsection{Thermodynamic Considerations}

The demon's operation is consistent with thermodynamic laws because it operates in categorical space, which is orthogonal to physical phase space.

\begin{theorem}[Demon Energy Cost]
The categorical memory demon incurs zero additional thermodynamic cost for categorical observation. The only energy costs are:
\begin{enumerate}
    \item Physical tier transitions (moving bits requires energy)
    \item Hardware timing measurements (negligible compared to normal operation)
\end{enumerate}
\end{theorem}

\begin{proof}
By Theorem \ref{thm:orthogonality}, categorical observables commute with physical observables. Measuring S-entropy coordinates does not disturb physical phase space and therefore incurs no thermodynamic cost beyond the measurement apparatus itself.

The precision-by-difference values are derived from hardware timing that occurs regardless of the memory controller's operation. The demon merely observes and interprets timing variations that are already present; it does not create them.

Energy is expended only when data physically moves between tiers (reading from one location, writing to another). This cost is identical to any tier management system. The demon's decisions about \textit{which} data to move incur no additional cost.
\end{proof}

\subsection{Controller State}

The controller maintains state for navigation and management decisions.

\begin{definition}[Controller State]
The controller state $\mathcal{S}_{\mathcal{C}}$ consists of:
\begin{itemize}
    \item Current S-entropy position: $\Scoord_{\text{current}}$
    \item Active S-entropy address: $\mathcal{A}_{\text{current}}$
    \item Tier contents: mapping from tier index to set of stored items
    \item Tier capacities: maximum items per tier
    \item Access statistics: hit/miss counts, latencies
\end{itemize}
\end{definition}

The current position evolves with each memory operation as new precision-by-difference values are recorded.

\subsection{Tier Management Policies}

\subsubsection{Promotion}

Promotion moves data from a slower tier to a faster tier.

\begin{definition}[Promotion Criterion]
A datum $D$ is promoted when its completion probability increases significantly:
\begin{equation}
P_{\text{completion}}(D, t) > \alpha \cdot P_{\text{completion}}(D, t - \Delta t)
\end{equation}
where $\alpha > 1$ is the promotion threshold (typically $\alpha = 1.5$).
\end{definition}

Completion probability measures how likely the datum is to be the categorical endpoint of the current trajectory. Increasing probability indicates the access pattern is converging toward this datum.

\begin{algorithmic}[1]
\Function{ConsiderPromotion}{datum $D$}
    \State $P_{\text{new}} \gets$ completion\_probability($D$, $\mathcal{A}_{\text{current}}$)
    \If{$P_{\text{new}} > \alpha \cdot D$.completion\_prob}
        \State $\text{tier}_{\text{new}} \gets D$.tier $- 1$ \Comment{Move to faster tier}
        \If{$\text{tier}_{\text{new}} \geq 0$}
            \State move($D$, $\text{tier}_{\text{new}}$)
        \EndIf
    \EndIf
    \State $D$.completion\_prob $\gets P_{\text{new}}$
\EndFunction
\end{algorithmic}

\subsubsection{Demotion}

Demotion moves data from a faster tier to a slower tier, typically to make room for promoted data.

\begin{definition}[Demotion Criterion]
A datum $D$ is selected for demotion when:
\begin{enumerate}
    \item Its current tier is at capacity, and
    \item It has the lowest completion probability among items in that tier.
\end{enumerate}
\end{definition}

\begin{algorithmic}[1]
\Function{SelectForDemotion}{tier $\mathcal{T}$}
    \State $P_{\min} \gets \infty$
    \State victim $\gets$ null
    \For{each $D$ in $\mathcal{T}$}
        \State $P \gets$ completion\_probability($D$, $\mathcal{A}_{\text{current}}$)
        \If{$P < P_{\min}$}
            \State $P_{\min} \gets P$
            \State victim $\gets D$
        \EndIf
    \EndFor
    \State \Return victim
\EndFunction
\end{algorithmic}

This policy demotes data that is categorically unlikely to be accessed, based on the current trajectory, rather than simply the least recently used data.

\subsubsection{Eviction}

When the slowest tier reaches capacity, data must be evicted entirely.

\begin{definition}[Eviction Policy]
Eviction removes data from the system entirely. Selection criteria:
\begin{enumerate}
    \item Already in the slowest tier (cannot be demoted further)
    \item Lowest completion probability (least likely to be needed)
    \item Oldest last access time (as tiebreaker)
\end{enumerate}
\end{definition}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/categorical_memory_operations_panel.png}
    \caption{
        \textbf{Categorical memory operations via Maxwell demon controller: Tier management, prefetching, and categorical completion achieve 100\% hit rate with zero evictions.} 
        \textbf{(A)} Memory tier hierarchy (bar chart, log scale, 5 tiers) shows capacity and usage. L1 Cache: capacity $10^2$ (blue bar), used 33 (green bar), hit rate 100.0\% (orange annotation, "33 hits"). L2 Cache: capacity $10^3$ (blue bar), used 0 (no green bar). RAM: capacity $10^4$ (blue bar), used 0. SSD: capacity $10^5$ (blue bar), used 0. Archive: capacity $10^5$ (blue bar), used 0. All accesses satisfied by L1 cache, validating categorical prefetching places data in correct tier before access.
        
        \textbf{(B)} Storage \& retrieval operations (bar chart, 20 hierarchy depths) shows uniform distribution. X-axis: hierarchy depth (6-20). Left y-axis: items stored (0-6). Right y-axis: normalized scale (0-1.0). Blue bars: stored items (1 per depth, uniform height). Green stars: retrieved items (4 retrievals at depths 6, 10, 16, 20). Annotation box (top-right): "Nodes: 258, Data: 20." Validates uniform storage distribution across hierarchy depths, with selective retrieval at specific depths.
        
        \textbf{(C)} Maxwell demon controller performance (horizontal bar chart, 4 metrics) shows zero-eviction operation. Evictions: 0 (no bar). Promotions: 0 (no bar). Total Hits: 33 (green bar, short). Active Addrs: 31 (purple bar, short). Total Calcs: 157 (blue bar, longest, annotation: "Mean $\Delta P$: $2.81 \times 10^{-6}$ s, Std $\Delta P$: $4.90 \times 10^{-7}$ s"). Zero evictions and promotions validate categorical completion predicts optimal tier placement, eliminating traditional cache management overhead. Mean $\Delta P$ of 2.81 Âµs indicates sub-microsecond precision for trajectory calculations.
        
        \textbf{(D)} Branch usage \& navigation paths (stacked bar chart, 3 levels) shows balanced branching. X-axis: hierarchy level (0, 1, 2). Y-axis: branch count (0-12). Branch 0 (green), Branch 1 (orange), Branch 2 (red). Level 0: 3 total (1+1+1). Level 1: 8 total (2+5+1). Level 2: 13 total (4+8+1). Annotation box (top): "Navigation Paths: alpha$\to$beta: 40 steps, alpha$\to$gamma: 38 steps, beta$\to$gamma: 40 steps." Branch 1 (orange, $\Delta P = 0$) most frequent at all levels, indicating temporal synchronization events dominate navigation. Validates balanced branch usage where all three $\Delta P$ conditions ($> 0$, $= 0$, $< 0$) contribute to addressing.
    }
    \label{fig:categorical_memory_operations}
\end{figure}


\subsection{Completion Probability Calculation}

The completion probability quantifies how likely a datum is to be the endpoint of the current trajectory.

\begin{definition}[Completion Probability]
For a datum $D$ with S-coordinate $\Scoord_D$ and a trajectory with predicted completion $\Scoord^*$:
\begin{equation}
P_{\text{completion}}(D) = \exp\left(-d_S(\Scoord_D, \Scoord^*)\right)
\end{equation}
where $d_S$ is the S-entropy distance.
\end{definition}

This exponential decay assigns high probability to data close to the predicted completion point and low probability to distant data.

\subsection{Categorical Distance as Tier Determinant}

\begin{proposition}[Distance-Tier Relationship]
The optimal tier for a datum $D$ is:
\begin{equation}
\text{tier}^*(D) = \min\left(T_{\max}, \left\lfloor c \cdot d_S(\Scoord_D, \Scoord_{\text{current}}) \right\rfloor\right)
\end{equation}
where $T_{\max}$ is the slowest tier index and $c$ is a scaling constant.
\end{proposition}

Data at zero categorical distance (current position) belongs in the fastest tier. Data at increasing distance belongs in progressively slower tiers.

\subsection{Controller Algorithm}

The complete controller algorithm integrates position tracking, tier management, and prediction:

\begin{algorithmic}[1]
\Function{ControllerStep}{}
    \State Update current position from precision samples
    \State Compute completion predictions for active trajectories
    \For{each datum $D$ accessed since last step}
        \State Update $D$.access\_count
        \State ConsiderPromotion($D$)
    \EndFor
    \If{any tier at capacity}
        \State Demote lowest-probability items
    \EndIf
    \State Prefetch high-probability items not in fast tiers
\EndFunction
\end{algorithmic}

The controller runs continuously, updating the memory organization in response to evolving access patterns.

\subsection{Synchronization}

Multiple concurrent accessors require synchronization to maintain consistent controller state.

\begin{definition}[Controller Lock]
A reentrant lock protects controller state modifications. All operations that modify tier contents, position, or statistics acquire this lock.
\end{definition}

The lock granularity is chosen to balance consistency with concurrency. Fine-grained locking per tier enables parallel access to different tiers; coarse-grained locking on the entire controller simplifies reasoning about state consistency.

