%==============================================================================
\section{Velocity-Entropy Independence: The Orthogonality of Motion and Arrangement}
\label{sec:velocity_entropy}
%==============================================================================

A final, decisive insight emerges from examining what entropy actually counts. The classical Boltzmann entropy $S = k_B \ln \Omega$ counts the number of microstates—the number of distinct arrangements accessible to the system. Crucially, arrangements are spatial configurations, not velocity distributions. Changing molecular velocities without changing spatial structure does not change the number of accessible arrangements and therefore does not change entropy. Velocity and entropy are orthogonal quantities in the sense that they are independent variables: knowledge of one does not determine the other, and changing one does not necessarily change the other. This orthogonality provides the most fundamental defeat of Maxwell's demon: the demon manipulates a quantity (velocity) that is categorically orthogonal to the quantity (entropy) protected by the Second Law. The demon's entire strategy operates in the wrong category, attempting to affect configurational properties (arrangements, entropy) by manipulating kinetic properties (velocities, kinetic energies). This category error renders the demon's strategy fundamentally ineffective, regardless of how efficiently the demon processes information or how precisely it measures velocities. The demon cannot decrease entropy by sorting velocities because entropy does not depend on velocities—it depends on spatial arrangements, which are independent of velocities.

\subsection{Entropy Counts Arrangements}

We begin by clarifying what entropy actually counts in the Boltzmann formulation, which is the foundation of statistical mechanics and the microscopic interpretation of the Second Law.

\begin{definition}[Boltzmann Entropy]
\label{def:boltzmann_entropy}
The Boltzmann entropy of a macrostate is defined as:
\begin{equation}
S = k_B \ln \Omega
\label{eq:boltzmann_entropy}
\end{equation}
where $\Omega$ is the number of microstates compatible with the macrostate, and $k_B$ is Boltzmann's constant. The macrostate specifies macroscopic observables (volume $V$, number of particles $N$, total energy $E$), while microstates specify the complete microscopic configuration of the system. The entropy quantifies the "multiplicity" of the macrostate: how many distinct microscopic ways the system can realize the same macroscopic properties.
\end{definition}

\begin{definition}[Microstate]
\label{def:microstate}
A microstate specifies the complete configuration of the system at the microscopic level. In the spatial interpretation relevant to categorical structure and entropy counting, a microstate is:
\begin{equation}
\text{Microstate} = \{\mathbf{r}_1, \mathbf{r}_2, \ldots, \mathbf{r}_N\}
\label{eq:microstate_spatial}
\end{equation}
where $\mathbf{r}_i$ is the position of molecule $i$ in three-dimensional space. More generally, in phase space, a microstate includes both positions and momenta: $\{\mathbf{r}_i, \mathbf{p}_i\}_{i=1}^N$. However, for entropy counting in the canonical ensemble (fixed temperature), the relevant microstates are spatial configurations, with momenta integrated out according to the Maxwell-Boltzmann distribution.
\end{definition}

\begin{remark}[Configuration Space vs. Phase Space]
\label{rem:configuration_phase}
The distinction between configuration space (positions only) and phase space (positions and momenta) is crucial for understanding entropy. In the microcanonical ensemble (fixed energy), entropy is computed by counting phase space volumes: $\Omega$ is the volume of the constant-energy surface in phase space. In the canonical ensemble (fixed temperature), entropy is computed by counting configuration space volumes: $\Omega$ is the number of spatial configurations, with momenta integrated out. For the purposes of Maxwell's demon (which operates at fixed temperature), the canonical ensemble is appropriate, and entropy counts spatial arrangements. The number of spatial arrangements $\Omega$ depends on how many ways molecules can be positioned in the available volume, subject to constraints (excluded volume, potential energy interactions, phase-lock correlations).
\end{remark}

The number of microstates $\Omega$ depends on how many ways molecules can be arranged spatially, not on how fast they move. This is the key insight: entropy is a configurational property (determined by positions), not a kinetic property (determined by velocities).

\begin{theorem}[Velocity Independence of Arrangement Count]
\label{thm:velocity_arrangement}
The number of spatial arrangements $\Omega$ is independent of molecular velocities. Formally, the partial derivative of $\Omega$ with respect to any velocity component is zero:
\begin{equation}
\frac{\partial \Omega}{\partial v_i} = 0 \quad \forall i
\label{eq:omega_velocity_independent}
\end{equation}
where $v_i = |\mathbf{v}_i|$ is the speed of molecule $i$. This independence holds for all molecules and all velocity components.
\end{theorem}

\begin{proof}
Spatial arrangements are determined by positions $\{\mathbf{r}_i\}_{i=1}^N$, not by velocities $\{\mathbf{v}_i\}_{i=1}^N$. Velocity is defined as the time derivative of position: $\mathbf{v}_i = d\mathbf{r}_i / dt$. Velocity determines the rate of change of position, not the position itself.

At any instant $t$, the positions $\{\mathbf{r}_i(t)\}$ determine the spatial arrangement. The velocities $\{\mathbf{v}_i(t)\}$ determine how rapidly positions will change in the future (how the arrangement will evolve), but they do not determine the current arrangement. Two systems with identical positions $\{\mathbf{r}_i\}$ but different velocities $\{\mathbf{v}_i\}$ have the same spatial arrangement at the current instant, even though their arrangements will differ at future instants.

The count $\Omega$ of distinct spatial configurations is determined by the following factors. First, the system volume $V$: larger volumes allow more distinct positions, increasing $\Omega$. Second, the number of molecules $N$: more molecules create more possible arrangements. Third, excluded volume interactions: molecules cannot overlap, reducing the number of accessible positions. Fourth, potential energy constraints: molecules avoid high-energy configurations (e.g., configurations with strong repulsive interactions), further reducing accessible positions. Fifth, phase-lock correlations: molecules in the same phase-lock cluster have correlated positions, creating additional constraints.

None of these factors depend on velocities. The volume $V$ is a geometric property. The number of molecules $N$ is fixed. Excluded volume depends on molecular size (hard-sphere diameter), not velocity. Potential energy depends on intermolecular distances $|\mathbf{r}_i - \mathbf{r}_j|$, not velocities. Phase-lock correlations depend on coupling strengths $\kappa_{ij}(\mathbf{r}_i, \mathbf{r}_j)$, which are functions of positions, not velocities (as established in Theorem~\ref{thm:kinetic_independence}).

Therefore, $\Omega$ is a function of positions alone: $\Omega = \Omega(\{\mathbf{r}_i\}, V, N, \text{interactions})$, with no dependence on velocities $\{\mathbf{v}_i\}$. The partial derivative with respect to velocity is:
\begin{equation}
\frac{\partial \Omega}{\partial v_i} = \frac{\partial}{\partial v_i} \Omega(\{\mathbf{r}_j\}, V, N, \text{interactions}) = 0
\end{equation}
since $\Omega$ does not contain $v_i$ as a variable.

Velocity and arrangement count are independent variables. Changing velocities does not change the number of arrangements. \qed
\end{proof}

\begin{corollary}[Velocity Independence of Entropy]
\label{cor:velocity_entropy_independent}
Entropy is independent of molecular velocities:
\begin{equation}
\frac{\partial S}{\partial v_i} = \frac{\partial}{\partial v_i} (k_B \ln \Omega) = \frac{k_B}{\Omega} \frac{\partial \Omega}{\partial v_i} = 0
\label{eq:entropy_velocity_independent}
\end{equation}
for all molecules $i$ and all velocity components. Entropy is a function of spatial configuration, not velocity distribution.
\end{corollary}

\begin{proof}
Direct consequence of Theorem~\ref{thm:velocity_arrangement}. Since $\partial \Omega / \partial v_i = 0$, and $S = k_B \ln \Omega$ is a function of $\Omega$ alone, the chain rule gives $\partial S / \partial v_i = (k_B / \Omega) (\partial \Omega / \partial v_i) = 0$. \qed
\end{proof}

\begin{remark}[Entropy vs. Kinetic Energy]
\label{rem:entropy_kinetic}
Corollary~\ref{cor:velocity_entropy_independent} establishes that entropy is independent of velocities and, therefore, independent of kinetic energy (since kinetic energy $E_{\text{kin}} = \sum_i (1/2) m_i v_i^2$ is a function of velocities). This independence is surprising from the perspective of traditional thermodynamics, which often conflates entropy with energy or temperature. The resolution is that entropy depends on the number of accessible configurations (a spatial property), while kinetic energy depends on the velocity distribution (a kinetic property). These are independent: a system can have high kinetic energy (high temperature) with low entropy (few accessible configurations, highly ordered), or low kinetic energy (low temperature) with high entropy (many accessible configurations, highly disordered). The independence is exact in the canonical ensemble, where temperature is fixed and entropy counts spatial configurations with momenta integrated out.
\end{remark}


\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/panel_arg4_dissolution_observation.png}
\caption{\textbf{Dissolution of Observation—Navigation Follows Topology, Not Velocity Measurement.}
\textbf{(A)} Topology determines path without velocity information. Molecules arranged in a phase-lock network (teal nodes) follow paths determined purely by network adjacency. The path from one side to the other (red nodes indicating transition region) is determined by categorical distance $d_{\text{cat}}(i,j)$ in the network, not by molecular velocities. Navigation occurs through shortest paths in the network graph, requiring no knowledge of kinetic properties.
\textbf{(B)} Observation not required for navigation. The diagram shows two information channels: velocity measurement (red, crossed out) and topological adjacency (green, active). Navigation proceeds through the green channel alone. The system follows network structure without any measurement of velocities, demonstrating that the demon's ``observation'' is unnecessary. Path completion is automatic through categorical structure.
\textbf{(C)} Velocity is uncorrelated with network position. Scatter plot of molecular velocity versus network position shows near-zero correlation ($r = -0.150$, dashed red line). The random scatter demonstrates that knowing a molecule's position in the phase-lock network provides no information about its velocity, and vice versa. This confirms that categorical distance $d_{\text{cat}}$ and kinetic distance $d_{\text{kin}}$ are inequivalent metrics, as stated in Section 3.4.
\textbf{(D)} Topological gate operates on adjacency, not velocity. Schematic of the demon's door showing two molecules (red circles) adjacent to the door and two molecules (blue squares) far from the door. The door opens based purely on topological adjacency in the phase-lock network: any adjacent molecule passes, regardless of velocity. The gate is velocity-blind, operating on categorical structure alone. This dissolves the paradox: there is no velocity measurement, no decision based on kinetic energy, and therefore no violation of the second law. The apparent ``sorting'' is categorical completion through network topology.}
\label{fig:dissolution_observation}
\end{figure*}

\subsection{The Snapshot Principle}

The velocity-entropy independence can be visualized through the concept of a configurational snapshot: a frozen instant capturing spatial positions but not velocities.

\begin{definition}[Configurational Snapshot]
\label{def:snapshot}
A \textbf{configurational snapshot} is the spatial arrangement of molecules at a specific instant $t$:
\begin{equation}
\mathcal{S}(t) = \{\mathbf{r}_1(t), \mathbf{r}_2(t), \ldots, \mathbf{r}_N(t)\}
\label{eq:snapshot}
\end{equation}
The snapshot records positions only, with no information about velocities, kinetic energies, or temperature. It is a "photograph" of the spatial configuration, frozen in time.
\end{definition}

\begin{theorem}[Snapshot Velocity Blindness]
\label{thm:snapshot_blind}
A configurational snapshot is velocity-blind: the same snapshot is compatible with any velocity distribution. Formally, for any snapshot $\mathcal{S}$ (set of positions) and any velocity distribution $\{\mathbf{v}_i\}$ satisfying basic physical constraints (e.g., total momentum conservation), there exists a physical state with positions $\mathcal{S}$ and velocities $\{\mathbf{v}_i\}$. The snapshot does not constrain velocities.
\end{theorem}

\begin{proof}
The snapshot $\mathcal{S}(t)$ records positions $\{\mathbf{r}_i(t)\}$ at instant $t$. It contains no information about the following kinetic properties. First, how fast molecules are moving: the speeds $v_i = |\mathbf{v}_i|$ are not recorded. Second, in what direction they are moving: the velocity vectors $\mathbf{v}_i$ are not recorded. Third, their kinetic energies: $E_i = (1/2) m_i v_i^2$ are not recorded. Fourth, the temperature of the system: $T = (2/3N k_B) \sum_i E_i$ is not recorded.

The snapshot is defined by positions alone: $\mathcal{S} = \{\mathbf{r}_i\}$. Positions and velocities are independent variables in phase space: specifying positions does not uniquely determine velocities. For any set of positions $\{\mathbf{r}_i\}$, there are infinitely many velocity distributions $\{\mathbf{v}_i\}$ that are physically realizable (subject only to conservation laws: total momentum $\sum_i m_i \mathbf{v}_i = \mathbf{P}_{\text{total}}$ and total energy $\sum_i (1/2) m_i v_i^2 + U(\{\mathbf{r}_i\}) = E_{\text{total}}$, where $U$ is the potential energy).

Therefore, the same spatial configuration $\mathcal{S}$ can exist with low velocities (low temperature), high velocities (high temperature), or any intermediate velocity distribution. The snapshot is compatible with any temperature $T \in (0, \infty)$. The snapshot does not constrain temperature. \qed
\end{proof}

\begin{corollary}[Temperature-Snapshot Independence]
\label{cor:temperature_snapshot}
A given snapshot can exist at any temperature:
\begin{equation}
\mathcal{S} \text{ is compatible with } T \in (0, \infty)
\label{eq:snapshot_temperature}
\end{equation}
Temperature does not constrain spatial arrangement, and spatial arrangement does not constrain temperature. The two are independent variables.
\end{corollary}

\begin{proof}
From Theorem~\ref{thm:snapshot_blind}, the snapshot $\mathcal{S}$ (positions) is compatible with any velocity distribution $\{\mathbf{v}_i\}$. Temperature is determined by the velocity distribution: $T = (2/3N k_B) \sum_i (1/2) m_i v_i^2$. Since any velocity distribution is compatible with $\mathcal{S}$, any temperature is compatible with $\mathcal{S}$. The range of compatible temperatures is $(0, \infty)$: arbitrarily low temperatures (all velocities near zero) and arbitrarily high temperatures (all velocities very large) are both compatible with the same spatial configuration. \qed
\end{proof}

\begin{example}[Crystalline Solid at Different Temperatures]
\label{ex:crystal_temperatures}
Consider a crystalline solid with molecules arranged in a regular lattice. The spatial configuration $\mathcal{S}$ is the lattice structure: molecules at positions $\mathbf{r}_i = \mathbf{R}_i + \mathbf{u}_i$, where $\mathbf{R}_i$ are the equilibrium lattice sites and $\mathbf{u}_i$ are small displacements (vibrations around equilibrium).

At low temperature ($T \to 0$), the velocities are small: $|\mathbf{v}_i| \to 0$. Molecules barely vibrate around their lattice sites. The spatial configuration is the lattice structure with small displacements.

At high temperature ($T \gg 0$), the velocities are large: $|\mathbf{v}_i| \sim \sqrt{k_B T / m}$. Molecules vibrate vigorously around their lattice sites. The spatial configuration is still the lattice structure (same average positions $\mathbf{R}_i$), but with larger displacements $|\mathbf{u}_i|$.

The snapshot $\mathcal{S}$ (lattice structure) is the same at both temperatures, even though the velocities differ by orders of magnitude. The entropy of the solid (determined by the number of accessible lattice configurations) is approximately the same at both temperatures (assuming the lattice structure is stable). The kinetic energy (and temperature) differs, but the entropy does not.

This example demonstrates that the same spatial configuration can exist at different temperatures, and entropy (which counts configurations) is independent of temperature (which measures kinetic energy).
\end{example}

\begin{remark}[Snapshot as Equivalence Class]
\label{rem:snapshot_equivalence}
The snapshot principle can be formalized using equivalence classes. Define an equivalence relation on phase space: two states $\Gamma_1 = \{\mathbf{r}_i, \mathbf{v}_i\}$ and $\Gamma_2 = \{\mathbf{r}_i', \mathbf{v}_i'\}$ are equivalent if they have the same positions: $\mathbf{r}_i = \mathbf{r}_i'$ for all $i$, regardless of velocities. The equivalence class $[\mathcal{S}]$ is the set of all states with positions $\mathcal{S}$:
\begin{equation}
[\mathcal{S}] = \{\Gamma = \{\mathbf{r}_i, \mathbf{v}_i\} : \mathbf{r}_i \in \mathcal{S} \text{ for all } i\}
\end{equation}

Each equivalence class corresponds to a snapshot. The entropy $S = k_B \ln \Omega$ counts the number of equivalence classes (snapshots), not the number of states within each class (velocity distributions). Changing velocities moves the system within an equivalence class but does not change which equivalence class the system occupies, and therefore does not change entropy.
\end{remark}

\subsection{Elastic Collisions: Temperature Without Entropy}

The velocity-entropy independence implies that processes that change velocities without changing spatial configurations do not change entropy. Elastic collisions are the paradigmatic example.

\begin{theorem}[Elastic Collision Entropy Invariance]
\label{thm:elastic_entropy}
Elastic collisions between molecules can change the velocity distribution (and therefore the temperature) without changing entropy. Formally, an elastic collision conserves kinetic energy and momentum but can redistribute velocities among molecules, changing the temperature locally or globally, while leaving the spatial configuration (and therefore the entropy) unchanged.
\end{theorem}

\begin{proof}
Consider an elastic collision between molecules $i$ and $j$ at time $t$.

\textbf{Before collision:}
The molecules have positions $\mathbf{r}_i(t^-)$ and $\mathbf{r}_j(t^-)$ (where $t^-$ denotes the instant just before collision) and velocities $\mathbf{v}_i(t^-)$ and $\mathbf{v}_j(t^-)$. The kinetic energies are:
\begin{align}
E_i &= \frac{1}{2} m_i |\mathbf{v}_i(t^-)|^2 \\
E_j &= \frac{1}{2} m_j |\mathbf{v}_j(t^-)|^2
\end{align}

\textbf{After collision:}
The molecules have positions $\mathbf{r}_i(t^+)$ and $\mathbf{r}_j(t^+)$ (where $t^+$ denotes the instant just after collision) and velocities $\mathbf{v}_i(t^+)$ and $\mathbf{v}_j(t^+)$. The kinetic energies are:
\begin{align}
E_i' &= \frac{1}{2} m_i |\mathbf{v}_i(t^+)|^2 \\
E_j' &= \frac{1}{2} m_j |\mathbf{v}_j(t^+)|^2
\end{align}

For an elastic collision, kinetic energy is conserved:
\begin{equation}
E_i + E_j = E_i' + E_j'
\label{eq:elastic_energy_conservation}
\end{equation}

Momentum is also conserved:
\begin{equation}
m_i \mathbf{v}_i(t^-) + m_j \mathbf{v}_j(t^-) = m_i \mathbf{v}_i(t^+) + m_j \mathbf{v}_j(t^+)
\label{eq:elastic_momentum_conservation}
\end{equation}

The velocities change: $\mathbf{v}_i(t^+) \neq \mathbf{v}_i(t^-)$ and $\mathbf{v}_j(t^+) \neq \mathbf{v}_j(t^-)$ (in general). The kinetic energies are redistributed: $E_i' \neq E_i$ and $E_j' \neq E_j$ (in general), subject to the constraint~\eqref{eq:elastic_energy_conservation}.

\textbf{Spatial arrangement:}
The collision occurs at a point in space where the molecules' trajectories intersect. The positions immediately before and after the collision are essentially the same: $\mathbf{r}_i(t^+) \approx \mathbf{r}_i(t^-)$ and $\mathbf{r}_j(t^+) \approx \mathbf{r}_j(t^-)$ (the collision duration is negligible, so positions do not change significantly during the collision). The spatial configuration of the entire system is unchanged: all other molecules have positions that are continuous through the collision time $t$.

\textbf{Number of arrangements:}
Since the spatial configuration is unchanged, the number of accessible spatial arrangements $\Omega$ is unchanged. The collision does not open new regions of configuration space or close existing regions. The set of accessible positions $\{\mathbf{r}_i\}$ is the same before and after the collision.

\textbf{Entropy:}
From the Boltzmann formula, $S = k_B \ln \Omega$. Since $\Omega$ is unchanged, entropy is unchanged:
\begin{equation}
S(t^+) = k_B \ln \Omega(t^+) = k_B \ln \Omega(t^-) = S(t^-)
\end{equation}

The collision is isentropic (constant entropy).

\textbf{Temperature:}
The temperature is determined by the average kinetic energy: $T = (2/3N k_B) \sum_{k=1}^{N} E_k$. If the collision redistributes kinetic energy such that the average changes (e.g., if molecule $i$ gains more energy than molecule $j$ loses, and molecule $i$ is in a region with many neighbors while molecule $j$ is isolated), then the local temperature can change. Globally, the total kinetic energy is conserved (equation~\eqref{eq:elastic_energy_conservation}), so the global average temperature is unchanged. But locally, temperature can increase in some regions and decrease in others.

Therefore, elastic collisions can change temperature (locally or through redistribution) without changing entropy. Temperature and entropy are independent: one can change while the other remains constant. \qed
\end{proof}

\begin{example}[Fast Molecules Become Faster]
\label{ex:fast_faster}
Consider an ensemble of molecules with a bimodal velocity distribution: some molecules are fast (velocity $v_{\text{fast}} \gg \langle v \rangle$) and some are slow (velocity $v_{\text{slow}} \ll \langle v \rangle$). Suppose fast molecules preferentially collide with each other (e.g., they are spatially localized near a boundary or in a cluster).

After elastic collisions among fast molecules, the velocity distribution within the fast group changes. Some fast molecules become even faster (they gain kinetic energy from collisions), while others become slower (they lose kinetic energy). The average kinetic energy of the fast group can increase if the collisions are asymmetric (e.g., if faster molecules tend to gain energy from slower molecules in the group).

The local "temperature" of the fast group, defined as the average kinetic energy, increases:
\begin{equation}
T_{\text{fast}}' = \frac{2}{3 N_{\text{fast}} k_B} \sum_{i \in \text{fast}} E_i' > \frac{2}{3 N_{\text{fast}} k_B} \sum_{i \in \text{fast}} E_i = T_{\text{fast}}
\end{equation}

Meanwhile, the spatial arrangement is unchanged: fast molecules remain in the same spatial region, slow molecules remain in their region. The number of accessible configurations $\Omega$ is unchanged. The entropy is unchanged:
\begin{equation}
S' = k_B \ln \Omega' = k_B \ln \Omega = S
\end{equation}

This example demonstrates that temperature can increase without entropy increasing. The increase is local (confined to the fast group) and temporary (it will eventually dissipate through collisions with the slow group, equilibrating the temperature). But at the instant after the collisions, temperature has increased while entropy has not.
\end{example}

\begin{remark}[Reversible vs. Irreversible Processes]
\label{rem:reversible_irreversible}
Theorem~\ref{thm:elastic_entropy}establishes that elastic collisions are isentropic (constant entropy), which might seem to contradict the Second Law (entropy increases in irreversible processes). The resolution is that elastic collisions are reversible processes: they conserve energy and momentum, and the time-reversed collision (with velocities reversed) is also a valid collision. Reversible processes do not increase entropy; only irreversible processes increase entropy. Irreversible processes involve dissipation (energy conversion to heat), mixing (bringing previously separated substances into contact), or other mechanisms that increase the number of accessible configurations. Elastic collisions do not involve these mechanisms, so they are reversible and isentropic. However, in practice, collisions are never perfectly elastic: there is always some energy dissipation (e.g., into internal degrees of freedom, or radiated away as photons). This dissipation makes collisions irreversible and entropy-increasing. The idealization of perfectly elastic collisions is useful for understanding the velocity-entropy independence but is not realized in nature.
\end{remark}

\subsection{Categorical Interpretation}

The velocity-entropy independence is immediate in the categorical framework, where entropy is determined by phase-lock network structure, which is independent of velocities.

\begin{theorem}[Categorical Velocity Independence]
\label{thm:categorical_velocity}
Categorical structure (phase-lock networks) is determined by spatial relationships, not velocities. Formally, the partial derivative of the categorical structure with respect to velocity is zero:
\begin{equation}
\frac{\partial \mathcal{C}}{\partial v_i} = 0
\label{eq:categorical_velocity_independent}
\end{equation}
where $\mathcal{C}$ denotes the categorical structure (the set of categorical states, the phase-lock network topology, the cluster structure, etc.). Categorical structure is a function of positions, not velocities.
\end{theorem}

\begin{proof}
Phase-lock networks form through intermolecular interactions that depend on spatial relationships. The relevant interactions are Van der Waals forces (depend on separation $|\mathbf{r}_i - \mathbf{r}_j|$ as $\sim 1/r^6$ for attraction and $\sim 1/r^{12}$ for repulsion), dipole-dipole interactions (depend on orientation and separation as $\sim \mathbf{d}_i \cdot \mathbf{d}_j / r^3$, where $\mathbf{d}_i$ is the dipole moment of molecule $i$), and vibrational coupling (depends on normal mode structure, which is determined by the Hessian matrix of the potential energy, a function of positions).

None of these interactions depend on translational velocity $\mathbf{v}_i$. Van der Waals forces are static (they depend on instantaneous positions, not on how positions are changing). Dipole interactions depend on molecular orientations, which are determined by rotational degrees of freedom (angular positions), not translational velocities. Vibrational coupling depends on the curvature of the potential energy surface around equilibrium positions, which is a function of positions, not velocities.

A phase-lock network is defined by which molecules are phase-locked to which: the edge set $E = \{(m_i, m_j) : \kappa_{ij} > \kappa_{\text{threshold}}\}$, where $\kappa_{ij}$ is the coupling strength between molecules $i$ and $j$. The coupling strength is determined by the interactions listed above, all of which depend on positions, not velocities. Therefore, the edge set $E$ (and hence the network topology $\phaselockgraph = (V, E)$) is a function of positions alone:
\begin{equation}
\phaselockgraph = \phaselockgraph(\{\mathbf{r}_i\}, \text{molecular properties})
\end{equation}
with no dependence on velocities $\{\mathbf{v}_i\}$.

Categorical structure $\mathcal{C}$ is the topology of this network: the set of categorical states (equivalence classes of spatial configurations determined by phase-lock relationships), the cluster structure (connected components of the network), the categorical pathways (adjacency relationships in categorical space), etc. All of these are determined by the network topology $\phaselockgraph$, which is determined by positions. Therefore, categorical structure is a function of positions, not velocities:
\begin{equation}
\mathcal{C} = \mathcal{C}(\phaselockgraph(\{\mathbf{r}_i\}))
\end{equation}

The partial derivative with respect to velocity is:
\begin{equation}
\frac{\partial \mathcal{C}}{\partial v_i} = \frac{\partial}{\partial v_i} \mathcal{C}(\phaselockgraph(\{\mathbf{r}_j\})) = 0
\end{equation}
since $\mathcal{C}$ does not contain $v_i$ as a variable.

Velocity and categorical structure are independent variables. Changing velocities does not change categorical structure. \qed
\end{proof}

\begin{corollary}[Categorical Entropy Velocity Independence]
\label{cor:categorical_entropy_velocity}
Categorical entropy (S-entropy) is independent of velocity:
\begin{equation}
\frac{\partial S_{\text{categorical}}}{\partial v_i} = 0
\label{eq:s_entropy_velocity_independent}
\end{equation}
for all molecules $i$ and all velocity components. Categorical entropy is determined by phase-lock network structure, which is independent of velocities.
\end{corollary}

\begin{proof}
From Proposition~\ref{prop:entropy_edge_density}, categorical entropy is proportional to the number of edges in the phase-lock network:
\begin{equation}
S_{\text{categorical}} \propto k_B |E(\phaselockgraph)|
\end{equation}

From Theorem~\ref{thm:categorical_velocity}, the network topology $\phaselockgraph$ (and therefore the edge count $|E|$) is independent of velocities: $\partial \phaselockgraph / \partial v_i = 0$. Therefore:
\begin{equation}
\frac{\partial S_{\text{categorical}}}{\partial v_i} \propto k_B \frac{\partial |E|}{\partial v_i} = 0
\end{equation}

Categorical entropy is velocity-independent. \qed
\end{proof}

\begin{remark}[Spatial vs. Kinetic Entropy]
\label{rem:spatial_kinetic_entropy}
Corollary~\ref{cor:categorical_entropy_velocity} establishes that categorical entropy (which counts phase-lock network configurations) is velocity-independent. This is consistent with Corollary~\ref{cor:velocity_entropy_independent}, which establishes that Boltzmann entropy (which counts spatial configurations) is velocity-independent. Both spatial entropy and categorical entropy are configurational properties, determined by positions (spatial or network), not by velocities (kinetic). This consistency validates the categorical framework: categorical entropy is a refinement of Boltzmann entropy (it counts categorical states, which are equivalence classes of spatial states), and both are velocity-independent because both count configurations, not velocities.
\end{remark}

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/velocity_entropy_panel.png}
\caption{\textbf{Velocity-Entropy Independence: The Demon's Category Error.}
\textbf{(A)} Entropy counts spatial arrangements, not velocities. Boltzmann's formula $S = k_B \ln(\Omega)$ where $\Omega$ is the number of spatial arrangements. Three example arrangements shown: Arrangement 1 (two molecules on left, one on right), Arrangement 2 (two molecules in center), Arrangement 3 (two molecules on right, one on left). Different positions yield different arrangements, but velocity is NOT included in the count. The same spatial configuration has the same entropy regardless of molecular velocities. This is the fundamental reason why velocity sorting cannot change entropy.
\textbf{(B)} Snapshot records positions only, not velocities or temperatures. Diagram shows six yellow molecules at fixed positions. Red text indicates "Velocities (ignored)". The same snapshot could represent a system at 100K or 1000K—the positional information is identical. Snapshots capture configurational state ($\Omega$), not kinetic state (velocity distribution). Therefore, entropy $S = k_B \ln(\Omega)$ depends only on what the snapshot shows: positions. Maxwell's demon observes velocities, but entropy depends on positions—this is the category error.
\textbf{(C)} Elastic collision: positions unchanged, velocities changed, entropy unchanged. Before collision: two molecules with velocities $v_1, v_2$ at collision point. After collision: same two molecules with velocities $v_1', v_2'$ (changed) at same collision point. Green box summarizes: Positions SAME (collision point unchanged), Velocities CHANGED, Temperature CAN CHANGE (kinetic energy redistributed), Entropy UNCHANGED (same spatial configuration). This proves that changing velocities—even dramatically—does not change entropy. The demon's velocity-sorting operation is thermodynamically irrelevant.
\textbf{(D)} Orthogonality of entropy and velocity. Two-dimensional diagram with "Config axis" (vertical, green) representing entropy and "Kinetic axis" (horizontal, red) representing velocity. The derivative $\partial S/\partial v = 0$ (shown at origin) indicates that entropy is independent of velocity. The two axes are orthogonal: changing velocity (horizontal motion) does not change entropy (vertical position). This geometric representation shows that kinetic and configurational properties inhabit orthogonal subspaces of the full state space.
\textbf{(E)} The demon's category error. Two boxes: "KINETIC" (purple, containing "Velocity, Momentum, Kinetic energy") and "CONFIGURATIONAL" (blue, containing "Position, Arrangement, Entropy"). Red "X" and "Demon tries" arrow between them indicates the demon attempts to manipulate kinetic properties to affect configurational properties. Text below: "Different categories! Manipulating kinetic properties cannot affect configurational properties." The demon operates in the wrong category—sorting by velocity (kinetic) cannot change arrangement count (configurational).
\textbf{(F)} What changes entropy versus what does not. Left box (green, "CHANGES S"): Mixing, Expansion, Chemical reaction, Phase change—all involve spatial rearrangement. Right box (red, "NO CHANGE"): Elastic collision, Velocity sorting, Adiabatic T change—all involve only velocity redistribution. Bottom text: "Spatial rearrangement = entropy change. Velocity redistribution = NO entropy change. Demon does velocity sorting!" This categorizes thermodynamic processes by their effect on entropy, clearly showing that the demon's operation (velocity sorting) is in the "no change" category.
\textbf{(G)} The demon's broken causal chain. Flow diagram: "Measure v" → "Sort by v" → "Change T" → "Change S?". Each arrow marked with red "X" indicating broken link. Text "without S!" shows that temperature can change without entropy change. Green box at bottom: "Change S?" with text "EVERY STEP BROKEN". The demon's intended causal chain (measure velocity → sort → change temperature → change entropy) is broken at every step. Measuring velocity doesn't determine entropy contribution, sorting by velocity doesn't sort by temperature (see Figure 8), changing temperature doesn't require changing entropy (adiabatic processes), and none of these operations change configurational entropy.
\textbf{(H)} The mathematical proof of velocity-entropy independence. Blue box contains: "$\Omega = f(\text{positions only})$, $\partial \Omega/\partial v_i = 0 \Rightarrow \partial S/\partial v_i = 0$". Text below: "Arrangement count is velocity-independent. Therefore entropy is velocity-independent. Velocity sorting has ZERO effect on entropy." This is the rigorous mathematical statement: since $\Omega$ (the quantity in Boltzmann's formula) depends only on positions, its derivative with respect to any velocity component $v_i$ is exactly zero, therefore entropy's derivative with respect to velocity is exactly zero. Velocity sorting cannot change entropy—not approximately, but exactly.
\textbf{(I)} The final defeat: orthogonality of velocity and entropy. Purple box: "VELOCITY and ENTROPY are ORTHOGONAL". Text below: "Velocity: rate of position change (kinetic). Entropy: count of arrangements (config). Demon sorts: velocities. 2nd law protects: entropy. The demon operates in the WRONG CATEGORY. Category error = fundamental defeat." This summarizes the resolution: velocity and entropy are orthogonal properties. The demon manipulates one (velocity) while the second law protects the other (entropy). The demon's defeat is not due to measurement costs or information erasure, but due to operating in the wrong category—a fundamental conceptual error in Maxwell's original formulation.}
\label{fig:velocity_entropy_independence}
\end{figure*}


\subsection{The Three-Way Orthogonality}

We now synthesize the results from this section and previous sections to establish a three-way orthogonality: velocity is orthogonal to temperature meaning, to entropy, and to heat flow direction.

\begin{theorem}[Velocity-Thermodynamic Orthogonality]
\label{thm:three_orthogonality}
Velocity is orthogonal to three fundamental thermodynamic quantities: temperature meaning, entropy, and heat flow direction. Formally:

\textbf{(1) Velocity $\perp$ Temperature meaning} (from Section~\ref{sec:velocity_overlap}): The same velocity has different "temperature contribution" in different ensembles. A molecule with velocity $v$ contributes differently to temperature depending on the molecular properties and phase-lock cluster membership of the ensemble. Temperature is not determined by velocity alone but by velocity in context.

\textbf{(2) Heat $\perp$ Entropy} (from Section~\ref{sec:heat_transfer}): Heat can flow in either direction (hot $\to$ cold or cold $\to$ hot) in individual molecular collisions, while entropy always increases. Heat flow direction is determined by kinetic energy transfer (a fluctuating kinetic property), while entropy increase is determined by categorical completion (a monotonic categorical property). The two are independent: heat can flow "backward" (cold $\to$ hot) while entropy still increases.

\textbf{(3) Velocity $\perp$ Entropy} (this section): Changing velocities does not change spatial arrangements, and therefore does not change entropy. Entropy counts configurations (a spatial property), while velocity measures motion (a kinetic property). The two are independent: velocity can change while entropy remains constant (elastic collisions), or entropy can change while velocity distribution remains constant (spatial rearrangement without kinetic energy change).

These three orthogonalities are independent and mutually reinforcing. Together, they establish that velocity (the quantity the demon measures and manipulates) is orthogonal to all thermodynamic quantities constrained by the Second Law.
\end{theorem}

\begin{proof}
We have established each orthogonality in previous sections.

\textbf{(1) Velocity $\perp$ Temperature meaning:}
From Theorem~\ref{thm:context_dependent} (Section~\ref{sec:velocity_overlap}), temperature is context-dependent: the same velocity $v$ contributes differently to temperature in different molecular ensembles. Specifically, for a molecule with velocity $v$ and mass $m$, the kinetic energy is $E = (1/2) m v^2$, but the temperature contribution depends on the ensemble's molecular properties. In an ensemble of light molecules (small $m$), a given velocity $v$ corresponds to low kinetic energy and low temperature contribution. In an ensemble of heavy molecules (large $m$), the same velocity corresponds to high kinetic energy and high temperature contribution.

Moreover, from Theorem~\ref{thm:apparent_sorting}, molecules in the same phase-lock cluster have correlated kinetic energies due to shared molecular properties, not because kinetic energy determines clustering. A molecule's temperature contribution depends on its cluster membership (which determines the ensemble context), not on its velocity alone.

Therefore, velocity does not uniquely determine temperature meaning. The mapping from velocity to temperature is many-to-one and context-dependent. Velocity and temperature meaning are orthogonal in the sense that knowing velocity does not determine temperature contribution without additional context.

\textbf{(2) Heat $\perp$ Entropy:}
From Theorem~\ref{thm:heat_entropy_decoupling} (Section~\ref{sec:heat_transfer}), heat flow direction and entropy change are fundamentally decoupled. Heat is a kinetic property (energy transfer), while entropy is a categorical property (configuration count). In individual molecular collisions, heat can flow in either direction (hot $\to$ cold or cold $\to$ hot) due to thermal fluctuations, while entropy always increases through categorical completion (phase-lock correlation formation).

The three cases analyzed in Section~\ref{sec:heat_transfer} demonstrate the independence:
\begin{itemize}
    \item Case 1 (elastic bounce-back): Heat flows hot $\to$ cold, entropy increases.
    \item Case 2 (inelastic, cold accelerates): Heat flows hot $\to$ cold, entropy increases.
    \item Case 3 (inelastic, cold decelerates): Heat flows cold $\to$ hot, entropy increases.
\end{itemize}

In all cases, entropy increases, but heat flow direction varies. The two quantities are independent: knowing heat flow direction does not determine entropy change, and knowing entropy change does not determine heat flow direction.

\textbf{(3) Velocity $\perp$ Entropy:}
From Theorem~\ref{thm:velocity_arrangement} (this section), entropy is independent of velocity: $\partial S / \partial v_i = 0$. Entropy counts spatial arrangements $\Omega$, which depend on positions $\{\mathbf{r}_i\}$, not velocities $\{\mathbf{v}_i\}$. Changing velocities does not change the number of accessible configurations, and therefore does not change entropy.

From Theorem~\ref{thm:elastic_entropy}, elastic collisions can change velocity distribution (and temperature) without changing entropy. This demonstrates that velocity and entropy are independent variables: one can change while the other remains constant.

\textbf{Mutual reinforcement:}
The three orthogonalities are mutually reinforcing. (1) implies that velocity does not determine temperature, so sorting by velocity does not sort by temperature. (2) implies that even if sorting by velocity did create a temperature difference (which it doesn't, by (1)), this would not necessarily decrease entropy because heat flow and entropy are decoupled. (3) implies that sorting by velocity cannot change entropy directly because velocity and entropy are independent.

Together, the three orthogonalities establish that velocity is orthogonal to all thermodynamic quantities constrained by the Second Law (temperature, heat flow, entropy). The demon manipulates velocity, which is orthogonal to the quantities protected by thermodynamics. \qed
\end{proof}

\begin{remark}[Geometric Interpretation of Orthogonality]
\label{rem:geometric_orthogonality}
The three-way orthogonality can be visualized geometrically. Consider a three-dimensional space with axes representing velocity $v$, temperature $T$, and entropy $S$. In classical thermodynamics, these three quantities are assumed to be related: velocity determines kinetic energy, kinetic energy determines temperature, and temperature determines entropy (through the Boltzmann distribution). This would make the three axes dependent, collapsing the three-dimensional space to a one-dimensional manifold (a curve).

But Theorem~\ref{thm:three_orthogonality} establishes that the three axes are independent (orthogonal). Velocity does not uniquely determine temperature (orthogonality 1), temperature does not uniquely determine entropy (orthogonality 2, via heat-entropy decoupling), and velocity does not uniquely determine entropy (orthogonality 3). The three axes span a full three-dimensional space, not a one-dimensional manifold.

The demon's strategy assumes the axes are dependent: it measures velocity (assuming this determines temperature) and sorts by velocity (assuming this changes entropy). But the axes are orthogonal, so the strategy fails: measuring velocity does not determine temperature, and sorting by velocity does not change entropy. The demon is trying to move along one axis (velocity) to affect another axis (entropy), but the axes are orthogonal, so movement along one does not affect the other.
\end{remark}

\subsection{Implications for the Demon}

The three-way orthogonality has devastating implications for Maxwell's demon's strategy.

\begin{theorem}[Complete Demon Strategy Failure]
\label{thm:complete_failure}
The demon's strategy is orthogonal to entropy at every level. The demon measures velocity (orthogonal to entropy), sorts by velocity (does not change arrangements), aims to change temperature (not entropy), while entropy depends on arrangements (not velocity or temperature). Each step of the demon's strategy operates on quantities that are orthogonal to the quantity constrained by the Second Law.
\end{theorem}

\begin{proof}
The demon's complete operation can be decomposed into four steps:
\begin{equation}
\text{Measure } v \to \text{Sort by } v \to \text{Change } T \to \text{(hope to change) } S
\label{eq:demon_strategy}
\end{equation}

We show that each arrow in this chain is broken—each step fails to achieve its intended effect because the quantities involved are orthogonal.

\textbf{Step 1: Measure $v$ $\to$ (determine) $T$:}
The demon measures velocity $v$ with the intention of determining which molecules are "hot" (high temperature contribution) and which are "cold" (low temperature contribution). But from orthogonality (1), velocity does not uniquely determine temperature meaning. The same velocity $v$ can correspond to different temperature contributions depending on molecular properties and cluster membership (Theorem~\ref{thm:context_dependent}).

Therefore, measuring velocity does not determine temperature contribution. The demon cannot classify molecules as "hot" or "cold" based on velocity alone. The first step of the strategy fails.

\textbf{Step 2: Sort by $v$ $\to$ (rearrange) configurations:}
The demon sorts molecules by velocity, allowing fast molecules to pass one way and slow molecules the other way. The intention is to rearrange the spatial configuration, creating a sorted state (fast molecules in one chamber, slow molecules in another).

But sorting by velocity does not necessarily rearrange spatial configurations. Velocity is the time derivative of position, not position itself. Two molecules can have the same position but different velocities (they are at the same place but moving at different speeds). Sorting by velocity rearranges which molecule has which velocity, not which molecule is at which position.

Moreover, from Theorem~\ref{thm:retrieval_paradox}, velocity-based sorting cannot be maintained against thermal equilibration. Velocities randomize on the collision timescale ($\sim 10^{-10}$ s), faster than sorting can occur. The demon enters an infinite loop of sorting and retrieval, never achieving a stable sorted state.

Therefore, sorting by velocity does not effectively rearrange configurations. The second step of the strategy fails.

\textbf{Step 3: Change $T$ $\to$ (change) $S$:}
Suppose the demon succeeded in changing temperature (creating a temperature difference between chambers). The intention is that this temperature change would correspond to an entropy change (decrease), violating the Second Law.

But from orthogonality (2), heat flow (which creates temperature differences) is decoupled from entropy change. Heat can flow in either direction while entropy always increases (Theorem~\ref{thm:heat_entropy_decoupling}). From Theorem~\ref{thm:elastic_entropy}, temperature can change without entropy changing (elastic collisions redistribute kinetic energy without changing spatial configurations).

Therefore, changing temperature does not necessarily change entropy. The third step of the strategy fails.

\textbf{Step 4: (hope to change) $S$:}
The ultimate goal is to decrease entropy, violating the Second Law. But from orthogonality (3), entropy is independent of velocity: $\partial S / \partial v_i = 0$ (Theorem~\ref{thm:velocity_arrangement}). Entropy depends on spatial arrangements, not velocities.

The demon's entire strategy operates on velocities (measuring, sorting, redistributing). But velocities are orthogonal to entropy. No manipulation of velocities can change entropy directly.

Therefore, the demon cannot decrease entropy by manipulating velocities. The final step of the strategy fails.

\textbf{Complete failure:}
Every step of the demon's strategy is broken. The demon measures a quantity (velocity) that does not determine what it needs to know (temperature contribution). It sorts by a quantity (velocity) that does not rearrange what it needs to rearrange (spatial configurations). It aims to change a quantity (temperature) that does not affect what it needs to affect (entropy). And the quantity it manipulates (velocity) is orthogonal to the quantity constrained by the Second Law (entropy).

The demon's strategy is orthogonal to entropy at every level. It is fundamentally misdirected, operating in the wrong category (kinetic properties) to affect the protected category (configurational properties). \qed
\end{proof}

\begin{corollary}[Demon's Category Error]
\label{cor:demon_category_error}
The demon commits a category error: it treats velocity (a kinetic property) as if it determined entropy (a configurational property). This category error renders the demon's strategy ineffective regardless of how efficiently the demon processes information or how precisely it measures velocities.
\end{corollary}

\begin{proof}
A category error is the mistake of treating a property of one type as if it were a property of another type. Examples include treating a number as if it were a color, treating a spatial coordinate as if it were a temporal coordinate, or treating a kinetic property as if it were a configurational property.

The demon's implicit assumption is:
\begin{equation}
\text{Sort by velocity} \implies \text{Change entropy}
\end{equation}

This assumes that velocity and entropy are in the same category—that manipulating one affects the other. But velocity is a kinetic property (rate of change of position: $\mathbf{v} = d\mathbf{r}/dt$), while entropy is a configurational property (count of arrangements: $S = k_B \ln \Omega(\{\mathbf{r}_i\})$). These are categorically distinct:

\begin{itemize}
    \item \textbf{Kinetic properties:} Derivatives of position with respect to time ($\dot{\mathbf{r}}$, $\ddot{\mathbf{r}}$, ...), kinetic energy ($E_{\text{kin}} = (1/2) m v^2$), momentum ($\mathbf{p} = m \mathbf{v}$), temperature ($T \propto \langle v^2 \rangle$).
    \item \textbf{Configurational properties:} Functions of position alone ($V(\{\mathbf{r}_i\})$, $\Omega(\{\mathbf{r}_i\})$, $S(\{\mathbf{r}_i\})$), potential energy ($U(\{\mathbf{r}_i\})$), phase-lock network topology ($\phaselockgraph(\{\mathbf{r}_i\})$).
\end{itemize}

Kinetic and configurational properties are independent variables in phase space. Specifying kinetic properties does not uniquely determine configurational properties, and vice versa. Manipulating kinetic properties does not necessarily affect configurational properties.

The demon's strategy is a category error: it manipulates kinetic properties (velocities) with the intention of affecting configurational properties (entropy). This is like trying to change the color of an object by changing its weight—the two properties are in different categories and are not causally related.

The category error renders the demon's strategy ineffective regardless of implementation details. Even if the demon has perfect information (knows all velocities exactly), infinite computational power (can process information instantaneously), and perfect control (can open and close the door with arbitrary precision), it still cannot decrease entropy by sorting velocities because velocity and entropy are in different categories. The strategy is fundamentally misdirected. \qed
\end{proof}

\subsection{What Actually Changes Entropy}

Having established what does not change entropy (velocity manipulations), we now clarify what does change entropy.

\begin{proposition}[Entropy-Changing Operations]
\label{prop:entropy_changing}
Operations that change entropy are those that change spatial arrangements or create new categorical relationships. Specifically:

\textbf{(1) Mixing:} Bringing previously separated molecules into the same spatial region creates new phase-lock correlations. The number of accessible configurations increases because molecules that could not interact before can now interact. Entropy increases: $\Delta S_{\text{mix}} = k_B \ln(\Omega_{\text{mixed}} / \Omega_{\text{separated}}) > 0$ (Theorem~\ref{thm:mixing_entropy}).

\textbf{(2) Expansion:} Allowing molecules access to new spatial regions increases the volume of configuration space. The number of accessible positions increases proportionally to the volume: $\Omega \propto V^N$. Entropy increases: $\Delta S_{\text{expansion}} = N k_B \ln(V_{\text{final}} / V_{\text{initial}}) > 0$ for $V_{\text{final}} > V_{\text{initial}}$.

\textbf{(3) Chemical reaction:} Creating new molecular species with different properties changes the phase-lock network structure. New edges form (between reactants and products), and old edges break (between reactants). The categorical structure changes, increasing entropy through network densification (Theorem~\ref{thm:reaction_entropy}).

\textbf{(4) Phase transition:} Reorganizing spatial structure (e.g., from solid to liquid, or liquid to gas) changes the number of accessible configurations. Melting increases entropy because liquid configurations are more numerous than solid configurations (molecules can move freely rather than being constrained to lattice sites). Entropy increases: $\Delta S_{\text{melt}} = L / T_{\text{melt}} > 0$, where $L$ is the latent heat of melting.

All of these operations change spatial arrangements or categorical relationships, and therefore change entropy.
\end{proposition}

\begin{proposition}[Non-Entropy-Changing Operations]
\label{prop:non_entropy_changing}
Operations that do NOT change entropy (in isolation) are those that change kinetic properties without changing spatial arrangements. Specifically:

\textbf{(1) Elastic collisions:} Redistribute velocity without changing positions. The velocity distribution changes, but the spatial configuration remains the same. Entropy is unchanged: $\Delta S_{\text{elastic}} = 0$ (Theorem~\ref{thm:elastic_entropy}).

\textbf{(2) Velocity sorting:} Rearranges which molecule has which velocity, not which molecule is at which position. If the spatial configuration is unchanged (molecules remain in the same positions, only their velocities are swapped), then entropy is unchanged. However, in practice, velocity sorting requires spatial rearrangement (moving molecules from one chamber to another), which does change entropy. The entropy change comes from the spatial rearrangement, not from the velocity sorting per se.

\textbf{(3) Adiabatic compression/expansion:} Changes temperature via work (compressing or expanding the gas) without heat transfer. The process is reversible and isentropic: $\Delta S_{\text{adiabatic}} = 0$. Temperature changes (increases during compression, decreases during expansion), but entropy remains constant because the process is reversible (no dissipation, no mixing, no irreversible spatial rearrangement).

These operations change kinetic properties (velocities, kinetic energies, temperature) without changing configurational properties (positions, arrangements, entropy).
\end{proposition}

\begin{remark}[Demon Performs Non-Entropy-Changing Operation]
\label{rem:demon_non_entropy}
The demon performs velocity sorting, which is a non-entropy-changing operation (Proposition~\ref{prop:non_entropy_changing}, item 2). The demon's intention is to sort molecules by velocity to create a temperature difference, hoping that this will decrease entropy. But velocity sorting does not change entropy directly because entropy depends on spatial arrangements, not velocities.

In practice, the demon's operation does change entropy, but the change is an increase, not a decrease. The entropy increase comes from categorical completion (phase-lock correlations created by the door operation) and network densification (new edges added to the effective phase-lock network), not from velocity sorting. The demon's strategy is doubly flawed: it performs an operation (velocity sorting) that does not change entropy, and when entropy does change (due to categorical effects), it increases rather than decreases.
\end{remark}

\subsection{The Demon's Category Error}

We now formalize the concept of category error and prove that the demon commits such an error.

\begin{definition}[Category Error]
\label{def:category_error}
A \textbf{category error} is the mistake of treating a property of one ontological category as if it were a property of another category, or of assuming that properties in different categories are causally related when they are actually independent. Formally, let $\mathcal{A}$ and $\mathcal{B}$ be two ontological categories (e.g., kinetic vs. configurational, spatial vs. temporal, physical vs. mental). A category error occurs when one assumes:
\begin{equation}
\text{Manipulate property in } \mathcal{A} \implies \text{Change property in } \mathcal{B}
\end{equation}
when in fact properties in $\mathcal{A}$ and $\mathcal{B}$ are independent (orthogonal).
\end{definition}

\begin{theorem}[Demon's Category Error]
\label{thm:category_error}
Maxwell's Demon commits a category error: it treats velocity (a kinetic property in category $\mathcal{K}$) as if it determined entropy (a configurational property in category $\mathcal{C}$), when in fact the two categories are independent (orthogonal).
\end{theorem}

\begin{proof}
Define two ontological categories:
\begin{align}
\mathcal{K} &= \{\text{kinetic properties: } \mathbf{v}, E_{\text{kin}}, T, \mathbf{p}, \text{etc.}\} \label{eq:category_kinetic} \\
\mathcal{C} &= \{\text{configurational properties: } \mathbf{r}, \Omega, S, \phaselockgraph, \text{etc.}\} \label{eq:category_configurational}
\end{align}

The demon's implicit assumption is:
\begin{equation}
\text{Sort by } v \in \mathcal{K} \implies \text{Change } S \in \mathcal{C}
\label{eq:demon_assumption}
\end{equation}

This assumes that kinetic and configurational categories are causally related: manipulating a kinetic property (velocity) changes a configurational property (entropy).

But from Theorem~\ref{thm:velocity_arrangement}, velocity and entropy are independent:
\begin{equation}
\frac{\partial S}{\partial v} = 0 \quad \implies \quad v \perp S
\end{equation}

The two categories are orthogonal: properties in $\mathcal{K}$ (kinetic) do not determine properties in $\mathcal{C}$ (configurational). Velocity is a kinetic property (rate of change of position), while entropy is a configurational property (count of arrangements). The two are independent variables in phase space.

Therefore, the demon's assumption~\eqref{eq:demon_assumption} is false. Sorting by velocity does not change entropy because velocity and entropy are in different, orthogonal categories. The demon commits a category error: it treats kinetic properties as if they determined configurational properties, when in fact the two categories are independent.

The category error is analogous to other well-known category errors in philosophy:
\begin{itemize}
    \item Treating mental properties as if they were physical properties (the mind-body category error).
    \item Treating numbers as if they were spatial objects (the abstract-concrete category error).
    \item Treating temporal properties as if they were spatial properties (the time-space category error).
\end{itemize}

In each case, the error arises from conflating two independent categories and assuming causal relationships that do not exist. The demon's category error is of the same type: conflating kinetic and configurational categories and assuming that manipulating one affects the other. \qed
\end{proof}

\begin{remark}[Category Error vs. Information Error]
\label{rem:category_vs_information}
The category error (Theorem~\ref{thm:category_error}) is distinct from the information-theoretic errors addressed in traditional resolutions of Maxwell's demon (Landauer's principle, Bennett's erasure). The information-theoretic resolutions argue that the demon fails because it must pay an entropy cost to acquire, store, or erase information. These resolutions assume that the demon's strategy is correct in principle (sorting by velocity would decrease entropy if information were free) but fails in practice due to information costs.

The category error resolution argues that the demon's strategy is incorrect in principle: sorting by velocity cannot decrease entropy even if information is free, because velocity and entropy are in different, orthogonal categories. The demon is trying to affect a configurational property (entropy) by manipulating a kinetic property (velocity), which is impossible because the two categories are independent.

The category error is more fundamental than the information error. Even if all information-theoretic objections were resolved (infinite memory, zero erasure cost, perfect measurement), the demon would still fail due to the category error. The demon's strategy is misdirected at a deeper level than information theory can address.
\end{remark}

\subsection{Summary}

Velocity and entropy are orthogonal: velocity is a kinetic property (rate of change of position), while entropy is a configurational property (count of arrangements). The two are independent variables, and changing one does not necessarily change the other.

Key results established in this section:

\textbf{(1) Entropy counts spatial arrangements, not velocities.} The Boltzmann entropy $S = k_B \ln \Omega$ counts the number of accessible configurations $\Omega$, which depends on positions $\{\mathbf{r}_i\}$, not velocities $\{\mathbf{v}_i\}$ (Theorem~\ref{thm:velocity_arrangement}).

\textbf{(2) A snapshot is velocity-blind.} The same spatial configuration can exist at any temperature. A configurational snapshot $\mathcal{S} = \{\mathbf{r}_i\}$ is compatible with any velocity distribution $\{\mathbf{v}_i\}$ (Theorem~\ref{thm:snapshot_blind}).

\textbf{(3) Elastic collisions change velocity without changing entropy.} Elastic collisions redistribute kinetic energy (changing temperature) without changing spatial configurations (leaving entropy unchanged) (Theorem~\ref{thm:elastic_entropy}).

\textbf{(4) Phase-lock networks depend on positions, not velocities.} Categorical structure is determined by spatial relationships (Van der Waals forces, dipole interactions, vibrational coupling), all of which depend on positions, not velocities (Theorem~\ref{thm:categorical_velocity}).

\textbf{(5) Three-way orthogonality.} Velocity is orthogonal to temperature meaning (same velocity has different temperature contribution in different contexts), to heat flow direction (heat can flow either way while entropy increases), and to entropy (changing velocity does not change arrangements) (Theorem~\ref{thm:three_orthogonality}).

\textbf{(6) Demon's strategy is orthogonal to entropy.} The demon measures velocity (orthogonal to entropy), sorts by velocity (does not change arrangements), aims to change temperature (not entropy), while entropy depends on arrangements (not velocity or temperature). Every step of the demon's strategy operates on quantities orthogonal to the quantity constrained by the Second Law (Theorem~\ref{thm:complete_failure}).

\textbf{(7) Demon commits a category error.} The demon treats velocity (kinetic property) as if it determined entropy (configurational property), when in fact the two categories are independent. This category error renders the demon's strategy fundamentally ineffective (Theorem~\ref{thm:category_error}).

The most fundamental defeat of Maxwell's demon is this: the demon manipulates a quantity (velocity) that is categorically orthogonal to the quantity (entropy) protected by the Second Law. The demon's entire strategy operates in the wrong category—kinetic rather than configurational. No amount of information processing, measurement precision, or computational power can overcome this fundamental misdirection. The demon is trying to affect entropy by manipulating velocities, which is impossible because velocity and entropy are independent, orthogonal quantities belonging to different ontological categories.

\begin{equation}
\boxed{
\begin{aligned}
\text{Velocity} &: \text{kinetic property (rate of change of position)} \\
\text{Entropy} &: \text{configurational property (count of arrangements)} \\
\frac{\partial S}{\partial v} &= 0 \quad \text{(orthogonal)} \\
\text{Demon's strategy} &: \text{category error (manipulates kinetic to affect configurational)}
\end{aligned}
}
\end{equation}
