%==============================================================================
\section{Triple Equivalence and Entropy Derivation}
\label{sec:entropy}
%==============================================================================

\subsection{Bounded Dynamics Implies Oscillation}

\begin{proposition}[Bounded Oscillation]
\label{prop:bounded_oscillation}
Any bounded dynamical system with continuous evolution exhibits oscillatory behavior.
\end{proposition}

\begin{proof}
Let the system occupy domain $\mathcal{D} \subset \mathbb{R}^{2N}$ with boundary $\partial\mathcal{D}$, where $N$ is the number of degrees of freedom. For measure-preserving dynamics, Liouville's theorem establishes volume conservation:
\begin{equation}
\frac{d}{dt}\int_{\mathcal{D}} d^{2N}z = 0
\end{equation}
where $z = (q, p)$ denotes phase space coordinates.

Since $\mathcal{D}$ is bounded, $\mu(\mathcal{D}) < \infty$. Poincar\'e recurrence theorem \cite{Poincare1890} states that for almost every initial condition $z_0 \in \mathcal{D}$, the trajectory returns arbitrarily close to $z_0$:
\begin{equation}
\forall \epsilon > 0, \; \exists T_{\text{rec}}: \quad \|z(T_{\text{rec}}) - z_0\| < \epsilon.
\end{equation}

For continuous dynamics, when trajectory $z(t)$ reaches $\partial\mathcal{D}$, it cannot escape (by boundedness). If it stops, no further dynamics occur (equilibrium). If it continues, it must reverse direction (reflection at boundary). By time-translation invariance, the reversed trajectory mirrors the outgoing trajectory. The system thus oscillates between boundary encounters with period $T = 2T_{\text{boundary}}$.
\end{proof}

\subsection{Oscillation Defines Categories}

\begin{definition}[Categorical State]
\label{def:category}
A categorical state $C_k$ is an equivalence class of phase space points indistinguishable at resolution $\delta$:
\begin{equation}
C_k = \{z \in \mathcal{D} : \|z - z_k\| < \delta\}
\end{equation}
where $z_k$ is a representative point.
\end{definition}

\begin{proposition}[Oscillation-Category Correspondence]
\label{prop:osc_cat}
Oscillatory motion with period $T$ observed at temporal resolution $\tau$ defines $n = T/\tau$ distinguishable categorical states.
\end{proposition}

\begin{proof}
Divide period $T$ into $n$ intervals $I_k = [k\tau, (k+1)\tau)$ for $k \in \{0, 1, \ldots, n-1\}$. At times $t_k = k\tau$, system occupies distinct phase space regions $z(t_k)$. Define category $C_k$ as equivalence class containing $z(t_k)$.

For $k \neq j$, if $\tau$ is chosen such that $\|z(t_k) - z(t_j)\| \geq \delta$, then $C_k \cap C_j = \emptyset$ (categories mutually exclusive). The oscillation traverses exactly $n$ distinguishable categories per period.

The correspondence $t_k \leftrightarrow C_k$ is bijective: each time sample corresponds to unique category, each category contains unique time sample. Information content identical: specifying $k \in \{0, \ldots, n-1\}$ requires $\log_2 n$ bits in both descriptions.
\end{proof}

\subsection{Categories Partition the Period}

\begin{definition}[Partition Cell]
\label{def:partition}
A partition cell $P_k$ is a temporal interval corresponding to one categorical state:
\begin{equation}
P_k = \{t \in [0, T) : z(t) \in C_k\}
\end{equation}
\end{definition}

\begin{proposition}[Category-Partition Correspondence]
\label{prop:cat_part}
The $n$ categorical states $\{C_0, \ldots, C_{n-1}\}$ correspond bijectively to $n$ partition cells $\{P_0, \ldots, P_{n-1}\}$ satisfying:
\begin{equation}
\bigcup_{k=0}^{n-1} P_k = [0, T), \quad P_i \cap P_j = \emptyset \; \text{for } i \neq j.
\end{equation}
\end{proposition}

\begin{proof}
For each category $C_k$, define partition cell $P_k = \{t : z(t) \in C_k\}$. Since trajectory $z(t)$ is continuous and categories are mutually exclusive, the sets $P_k$ form a partition of $[0, T)$.

Map $\phi: C_k \mapsto P_k$ is bijective:
\begin{itemize}
\item Injective: $C_i \neq C_j \Rightarrow P_i \cap P_j = \emptyset \Rightarrow P_i \neq P_j$
\item Surjective: Every $t \in [0, T)$ satisfies $z(t) \in C_k$ for some $k$, hence $t \in P_k$
\end{itemize}

The partition cells have durations $|P_k| = \tau_k$ satisfying $\sum_{k=0}^{n-1} \tau_k = T$. Average partition duration:
\begin{equation}
\langle\tau_p\rangle = \frac{1}{n}\sum_{k=0}^{n-1} \tau_k = \frac{T}{n}
\end{equation}
\end{proof}

\subsection{Proof of Triple Equivalence}

\begin{proof}[Proof of Theorem \ref{thm:triple_equivalence}]
We have established three bijections:
\begin{align}
\phi_{OC}: \{t_k\} &\leftrightarrow \{C_k\} \quad \text{(oscillatory $\leftrightarrow$ categorical)} \\
\phi_{CP}: \{C_k\} &\leftrightarrow \{P_k\} \quad \text{(categorical $\leftrightarrow$ partition)} \\
\phi_{PO}: \{P_k\} &\leftrightarrow \{t_k\} \quad \text{(partition $\leftrightarrow$ oscillatory)}
\end{align}

By transitivity, all three descriptions are equivalent. Each has exactly $n$ distinguishable elements.

Quantitative identity follows from definitions. Rate of category traversal:
\begin{equation}
\frac{dM}{dt} = \frac{n}{T}
\end{equation}

For oscillatory motion with frequency $\omega = 2\pi/T$:
\begin{equation}
\frac{\omega}{2\pi/n} = \frac{2\pi/T}{2\pi/n} = \frac{n}{T}
\end{equation}

For partition duration $\langle\tau_p\rangle = T/n$:
\begin{equation}
\frac{1}{\langle\tau_p\rangle} = \frac{n}{T}
\end{equation}

Therefore:
\begin{equation}
\frac{dM}{dt} = \frac{\omega}{2\pi/M} = \frac{1}{\langle\tau_p\rangle}
\end{equation}

The three perspectives yield identical quantitative predictions.
\end{proof}

\subsection{Categorical Entropy}

\begin{definition}[Categorical Entropy]
\label{def:categorical_entropy}
For a system with $M$ categorical dimensions, each admitting $n$ distinguishable states, the categorical entropy is:
\begin{equation}
S_{\text{cat}} = \kB M \ln n
\end{equation}
where $\kB$ is Boltzmann's constant.
\end{definition}

\begin{theorem}[Categorical Entropy Formula]
\label{thm:categorical_entropy}
Categorical entropy counts the number of distinguishable configurations:
\begin{equation}
S_{\text{cat}} = \kB \ln \Omega, \quad \Omega = n^M
\end{equation}
\end{theorem}

\begin{proof}
For $M$ independent categorical dimensions, each with $n$ states, total number of configurations:
\begin{equation}
\Omega = \underbrace{n \times n \times \cdots \times n}_{M \text{ times}} = n^M
\end{equation}

By Boltzmann's formula $S = \kB \ln \Omega$:
\begin{equation}
S_{\text{cat}} = \kB \ln(n^M) = \kB M \ln n
\end{equation}
\end{proof}

\subsection{Oscillatory Entropy}

\begin{definition}[Oscillatory Entropy]
\label{def:oscillatory_entropy}
For a system with oscillatory modes having amplitudes $\{A_i\}$ relative to reference amplitude $A_0$, the oscillatory entropy is:
\begin{equation}
S_{\text{osc}} = \kB \sum_{i=1}^{M} \ln\left(\frac{A_i}{A_0}\right)
\end{equation}
\end{definition}

\begin{theorem}[Oscillatory Entropy Equivalence]
\label{thm:oscillatory_entropy}
For oscillators with equal amplitude ratios $A_i/A_0 = n$:
\begin{equation}
S_{\text{osc}} = S_{\text{cat}}
\end{equation}
\end{theorem}

\begin{proof}
Substitute $A_i/A_0 = n$ into oscillatory entropy:
\begin{equation}
S_{\text{osc}} = \kB \sum_{i=1}^{M} \ln n = \kB M \ln n = S_{\text{cat}}
\end{equation}

Physical interpretation: amplitude ratio $A_i/A_0$ measures accessible phase space volume. For oscillator confined to amplitude $A_i$, accessible volume scales as $V \propto A_i^d$ where $d$ is dimensionality. Number of distinguishable states within volume:
\begin{equation}
n_i = \frac{V_i}{V_0} = \left(\frac{A_i}{A_0}\right)^d
\end{equation}

For one-dimensional oscillator ($d = 1$), $n_i = A_i/A_0$, confirming correspondence between amplitude ratio and state count.
\end{proof}

\subsection{Partition Entropy}

\begin{definition}[Partition Selectivity]
\label{def:selectivity}
For partition operation $\Pi_a$ selecting subset $S_a \subset S$ from full space $S$, selectivity is:
\begin{equation}
s_a = \frac{\mu(S_a)}{\mu(S)}
\end{equation}
where $\mu$ denotes measure.
\end{definition}

\begin{definition}[Partition Entropy]
\label{def:partition_entropy}
For sequence of partition operations $\{\Pi_a\}$ with selectivities $\{s_a\}$, the partition entropy is:
\begin{equation}
S_{\text{part}} = \kB \sum_{a} \ln\left(\frac{1}{s_a}\right) = -\kB \sum_{a} \ln s_a
\end{equation}
\end{definition}

\begin{theorem}[Partition Entropy Equivalence]
\label{thm:partition_entropy}
For $M$ partition operations each with selectivity $s = 1/n$:
\begin{equation}
S_{\text{part}} = S_{\text{cat}}
\end{equation}
\end{theorem}

\begin{proof}
Each partition operation divides space into $n$ equal cells, selecting one with selectivity $s = 1/n$. For $M$ operations:
\begin{equation}
S_{\text{part}} = \kB \sum_{a=1}^{M} \ln\left(\frac{1}{1/n}\right) = \kB M \ln n = S_{\text{cat}}
\end{equation}

Physical interpretation: partition operation asks question "which of $n$ subcells contains the state?" Information gained is $\ln n$ nats. For $M$ independent questions, total information:
\begin{equation}
I = M \ln n = \frac{S_{\text{cat}}}{\kB}
\end{equation}

Thermodynamic entropy equals information-theoretic entropy multiplied by $\kB$, establishing Landauer's principle at the foundational level.
\end{proof}

\subsection{Unified Entropy Theorem}

\begin{theorem}[Entropy Equivalence]
\label{thm:entropy_equivalence}
For bounded dynamical systems, categorical, oscillatory, and partition entropies are identical:
\begin{equation}
S_{\text{cat}} = S_{\text{osc}} = S_{\text{part}} = \kB M \ln n
\end{equation}
\end{theorem}

\begin{proof}
Theorems \ref{thm:categorical_entropy}, \ref{thm:oscillatory_entropy}, and \ref{thm:partition_entropy} establish that all three formulations yield $\kB M \ln n$ under appropriate correspondences:
\begin{itemize}
\item Categorical: Direct state counting
\item Oscillatory: Amplitude ratios $A_i/A_0 = n$
\item Partition: Selectivities $s_a = 1/n$
\end{itemize}

These correspondences are not arbitrary but follow from the triple equivalence (Theorem \ref{thm:triple_equivalence}). Categories, oscillations, and partitions describe identical structure, therefore their entropy formulations must agree.

The unified formula $S = \kB M \ln n$ applies to any bounded system independent of microscopic details. Entropy depends only on:
\begin{itemize}
\item Number of categorical dimensions $M$ (degrees of freedom)
\item Number of distinguishable states per dimension $n$ (resolution)
\end{itemize}

Temperature, volume, particle count determine $M$ and $n$ but do not appear explicitly in the formula. This establishes entropy as fundamentally geometric rather than thermodynamic.
\end{proof}

\subsection{Connection to Statistical Mechanics}

\begin{corollary}[Boltzmann Formula]
\label{cor:boltzmann}
The categorical entropy formula recovers Boltzmann's formula:
\begin{equation}
S = \kB \ln \Omega
\end{equation}
with $\Omega = n^M$ representing the total number of microstates.
\end{corollary}

\begin{corollary}[Gibbs Entropy]
\label{cor:gibbs}
For non-uniform probability distribution $\{p_k\}$ over $n^M$ states, Gibbs entropy:
\begin{equation}
S_{\text{Gibbs}} = -\kB \sum_{k=1}^{n^M} p_k \ln p_k
\end{equation}
reduces to categorical entropy for uniform distribution $p_k = 1/n^M$:
\begin{equation}
S_{\text{Gibbs}} = -\kB \sum_{k=1}^{n^M} \frac{1}{n^M} \ln\frac{1}{n^M} = \kB \ln(n^M) = S_{\text{cat}}
\end{equation}
\end{corollary}

\begin{corollary}[Third Law]
\label{cor:third_law}
At zero temperature, all systems relax to ground state ($M = 0$ active categories):
\begin{equation}
\lim_{T \to 0} S = \kB \cdot 0 \cdot \ln n = 0
\end{equation}
recovering the third law of thermodynamics without requiring quantum mechanical arguments.
\end{corollary}

The triple equivalence thus provides complete foundation for statistical mechanics, deriving Boltzmann, Gibbs, and third law from pure geometry of bounded phase space.
